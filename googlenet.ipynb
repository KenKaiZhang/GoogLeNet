{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of GoogLeNet that won the **\"ImageNet Classification with Deep Convolutional Neural Networkds\"** in 2014. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Project\n",
    "\n",
    "Let's start by downloading the necessary libraries from `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's import the requried libraries into our notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Optional, Tuple, Any\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from troch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since training will be on in a different file and use the modules from this file, let's state which module should be exported if a were to utilize this one. By setting an `__all__`, we can let Python know that any other modules (functions, classes, etc) that exists in the file but outside the list should not be accessible by files that will utilize this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"GoogleNetOutputs\",\"GoogLeNet\", \"BasicConv2d\", \"Inception\", \"InceptionAux\", \"googlenet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with organization with the model's outputs, we explicitly define what we want our model output to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogLeNetOutputs = namedtuple(\"GoogLeNetOutputs\", [\"logits\", \"aux_logits2\", \"aux_logits1\"])\n",
    "GoogLeNetOutputs.__annotations__ = {\n",
    "    \"logits\": Tensor,\n",
    "    \"aux_logits2\": Optional[Tensor],\n",
    "    \"aux_logits1\": Optional[Tensor]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the code above, we state that we want our outputs to be stored in the variable `GoogLeNetOutputs` where the data contained should be a tuple of 3 `Tensor`s where 2 of them can either be a `Tenor` or `None`.\n",
    "\n",
    "With that, we can begin building GoogLeNet model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2736618250.py, line 102)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 102\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    __constants__ = [\"aux_logits\", \"transform_input\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 1000,\n",
    "        aux_logits: bool = True,\n",
    "        transform_input: bool = False,\n",
    "        dropout: float = 0.2,\n",
    "        dropout_aux: float = 0.7\n",
    "    ) -> None:\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "\n",
    "        self.conv1 = BasicConv2d(2, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n",
    "        self.maxpool1 = nn.MaxPool2d((3,3), (2,2), ceil_mode=True)\n",
    "        self.conv2 = BasicConv2d(64, 64, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
    "        self.conv3 = BasicConv2d(64, 192, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.maxpool2 = nn.MaxPool2d((3,3), (2,2), ceil_mode=True)\n",
    "\n",
    "        self.inception3a = Inception(192, 64, 98, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d((3,3), (2,2), ceil_mode=True)\n",
    "\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 48)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d((2,2), (2,2), ceil_mode=True)\n",
    "\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        if aux_logits:\n",
    "            self.aux1 = InceptionAux(512, num_classes, dropout_aux)\n",
    "            self.aux2 = InceptionAux(528, num_classes, dropout_aux)\n",
    "        else:\n",
    "            self.aux1 = None\n",
    "            self.aux2 = None\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(dropout, True)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def eager_outputs(self, x: Tensor, aux2: Tensor, aux1: Optional[Tensor]) -> GoogLeNetOutputs | Tensor:\n",
    "        if self.training and self.aux_logits:\n",
    "            return GoogLeNetOutputs(x, aux2, aux1)\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n",
    "        out = self._forward_impl(x)\n",
    "        return out\n",
    "    \n",
    "    def _transform_input(self, x: Tensor) -> Tensor:\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        return x\n",
    "    \n",
    "    def _forward_imp1(self, x: Tensor) -> GoogLeNetOutputs:\n",
    "        x = self._transform_input(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        out = self.inception3a(out) \n",
    "        out = self.inception3b(out)\n",
    "        out = self.maxpool3(out)\n",
    "        out = self.inception4a(out)\n",
    "        aux1: Optional[Tensor] = self.aux1(out) if self.aux1 is not None and self.training else None\n",
    "\n",
    "        out = self.inception4b(out)\n",
    "        out = self.inception4c(out)\n",
    "        out = self.inception4d(out)\n",
    "        aux2: Optional[Tensor] = self.aux2(out) if self.aux1 is not None and self.training else None\n",
    "\n",
    "        out = self.inception4e(out) \n",
    "        out = self.maxpool4(out)\n",
    "        out = self.inception5a(out)\n",
    "        out = self.inception5b(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.dropout(out)\n",
    "        aux3 = self.fc(out)\n",
    "\n",
    "        if torch.jit.is_scripting():\n",
    "            return GoogLeNetOutputs(aux3, aux2, aux1)\n",
    "        else:\n",
    "            return self.eager_outputs(aux3, aux2, aux1)\n",
    "        \n",
    "    def _initialize_weights(self) -> None:\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                torch.nn.init.trunc_normal_(module.weight, mean=0.0, std=0.1, a=-1, b=2)\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
